{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Authors: [Vitaly Radchenko](https://www.linkedin.com/in/vitaliyradchenk0/), Data Scientist at YouScan, and , Data Scientist at Mail.ru Group <br>\n",
    "Translated and edited by [Yury Kashnitskiy](https://www.linkedin.com/in/festline/), [Egor Polusmak](https://www.linkedin.com/in/egor-polusmak/), [Christina Butsko](https://www.linkedin.com/in/christinabutsko/), [Anna Shirshova](http://linkedin.com/in/anna-shirshova-b908458b), [Artem Trunov](https://www.linkedin.com/in/datamove/),  and [Yuanyuan Pao](https://www.linkedin.com/in/yuanyuanpao/).\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment # 5</center>\n",
    "## <center>Logistic Regression and Random Forest in the credit scoring problem</center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build models and answer questions using data on credit scoring.\n",
    "\n",
    "Please write your code in the cells with the \"Your code here\" placeholder. Then, answer some questions in this [form](https://drive.google.com/open?id=1P9SAkIRUiznVJd1bzAqRG5AoIpwPfUo3SHfQtDV_tPw).\n",
    "\n",
    "Let's start with a warm-up exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** There are 5 jurors in a courtroom. Each of them can correctly identify the guilt of the defendant with 70% probability, independent of one another. What is the probability that the jurors will jointly reach the correct verdict if the final decision is made by majority vote?\n",
    "\n",
    "1. 70.00%\n",
    "2. 83.20%\n",
    "3. **83.70%**\n",
    "4. 87.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.7\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "n = 5\n",
    "m = (n + 1) / 2\n",
    "prob = 0.7\n",
    "mu = 0\n",
    "def comb(i, N):\n",
    "    return factorial(N)/(factorial(i)*factorial(N-i))\n",
    "\n",
    "for i in range(int(m), n+1):\n",
    "    mu += comb(i, n) * prob**i * (1 - prob)**(n-i)\n",
    "\n",
    "print(round(mu * 100, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's move on to machine learning.\n",
    "\n",
    "## Credit scoring problem setup\n",
    "\n",
    "#### Problem\n",
    "\n",
    "Predict whether the customer will repay his/her credit within 90 days. This is a binary classification problem; we will assign customers into good or bad categories based on our prediction.\n",
    "\n",
    "#### Data description\n",
    "\n",
    "| Feature | Variable Type | Value Type | Description |\n",
    "|:--------|:--------------|:-----------|:------------|\n",
    "| age | Input Feature | integer | Customer age |\n",
    "| DebtRatio | Input Feature | real | Total monthly loan payments (loan, alimony, etc.) / Total monthly income percentage |\n",
    "| NumberOfTime30-59DaysPastDueNotWorse | Input Feature | integer | The number of cases when client has overdue 30-59 days (not worse) on other loans during the last 2 years |\n",
    "| NumberOfTimes90DaysLate | Input Feature | integer | Number of cases when customer had 90+dpd overdue on other credits |\n",
    "| NumberOfTime60-89DaysPastDueNotWorse | Input Feature | integer | Number of cased when customer has 60-89dpd (not worse) during the last 2 years |\n",
    "| NumberOfDependents | Input Feature | integer | The number of customer dependents |\n",
    "| SeriousDlqin2yrs | Target Variable | binary: <br>0 or 1 | Customer hasn't paid the loan debt within 90 days |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings in Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 11, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the function that will replace *NaN* values with a median for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(table):\n",
    "    for col in table.columns:\n",
    "        table[col] = table[col].fillna(table[col].median())\n",
    "    return table   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6666.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  age  NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  \\\n",
       "0                 0   64                                     0     0.249908   \n",
       "1                 0   58                                     0  3870.000000   \n",
       "2                 0   41                                     0     0.456127   \n",
       "3                 0   43                                     0     0.000190   \n",
       "4                 1   49                                     0     0.271820   \n",
       "\n",
       "   NumberOfTimes90DaysLate  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                        0                                     0   \n",
       "1                        0                                     0   \n",
       "2                        0                                     0   \n",
       "3                        0                                     0   \n",
       "4                        0                                     0   \n",
       "\n",
       "   MonthlyIncome  NumberOfDependents  \n",
       "0         8158.0                 0.0  \n",
       "1            NaN                 0.0  \n",
       "2         6666.0                 0.0  \n",
       "3        10500.0                 2.0  \n",
       "4          400.0                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/credit_scoring_sample.csv', sep =';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the variable types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                          int64\n",
       "age                                       int64\n",
       "NumberOfTime30-59DaysPastDueNotWorse      int64\n",
       "DebtRatio                               float64\n",
       "NumberOfTimes90DaysLate                   int64\n",
       "NumberOfTime60-89DaysPastDueNotWorse      int64\n",
       "MonthlyIncome                           float64\n",
       "NumberOfDependents                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check target variable distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the target:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.777511\n",
       "1    0.222489\n",
       "Name: SeriousDlqin2yrs, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e02c3d4c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = data['SeriousDlqin2yrs'].hist(orientation='horizontal', color='red')\n",
    "ax.set_xlabel(\"number_of_observations\")\n",
    "ax.set_ylabel(\"unique_value\")\n",
    "ax.set_title(\"Target distribution\")\n",
    "\n",
    "print('Distribution of the target:')\n",
    "data['SeriousDlqin2yrs'].value_counts()/data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to replace *NaN* values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = fill_nan(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable and input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = table.drop('SeriousDlqin2yrs', axis=1)\n",
    "y = table['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Make an interval estimate of the average age for the customers who delayed repayment at the 90% confidence level. Use the example from the article as reference, if needed. Also, use `np.random.seed(0)` as it was done in the article. What is the resulting interval estimate?\n",
    "\n",
    "1. 52.59 – 52.86\n",
    "2. **45.71 – 46.13**\n",
    "3. 45.68 – 46.17\n",
    "4. 52.56 – 52.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.71, 46.13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "np.random.seed(0)\n",
    "\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    \"\"\"Generate bootstrap samples using the bootstrap method.\"\"\"\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "\n",
    "def stat_intervals(stat, alpha):\n",
    "    \"\"\"Produce an interval estimate.\"\"\"\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries\n",
    "\n",
    "X_age = table[table['SeriousDlqin2yrs'] == 1]['age'].values\n",
    "\n",
    "delayed_mean_age = [np.mean(sample) for sample in get_bootstrap_samples(X_age, 5000)]\n",
    "np.around(stat_intervals(delayed_mean_age, 0.1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create a `LogisticRegression` model and use `class_weight='balanced'` to make up for our unbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=5, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find the best regularization coefficient, which is the coefficient `C` for logistic regression. Then, we will have an optimal model that is not overfit and is a good predictor of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': (0.0001, 0.001, 0.01, 0.1, 1, 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the optimal value of `C`, let's apply stratified 5-fold validation and look at the *ROC AUC* against different values of the parameter `C`. Use the `StratifiedKFold` function for this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the important metrics of model quality is the *Area Under the Curve (AUC)*. *ROC AUC* varies from 0 to 1. The closer ROC AUC is to 1, the better the quality of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 3.** Perform a *Grid Search* with the scoring metric \"roc_auc\" for the parameter `C`. Which value of the parameter `C` is optimal? \n",
    "\n",
    "1. 0.0001\n",
    "2. **0.001**\n",
    "3. 0.01\n",
    "4. 0.1\n",
    "5. 1\n",
    "6. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
       "           solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       " 0.7954977787123253)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "clf = GridSearchCV(lr, parameters, cv=skf, scoring='roc_auc', verbose=1).fit(X.values, y.values)\n",
    "print(clf.best_params_) \n",
    "clf.best_estimator_, clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Can we consider the best model stable? Let's call the model *stable* if standard deviation of it's scores in cross-validation is less than $5*10^{-3}$. Save the *ROC AUC* value of the best model; it will be useful for the following tasks.\n",
    "\n",
    "1. Yes\n",
    "2. **No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7954977787123253 0.006381449381361704\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "best_score_idx = np.argmin(clf.cv_results_['rank_test_score'])\n",
    "best_model_roc_auc = clf.cv_results_['mean_test_score'][best_score_idx]\n",
    "best_model_std = clf.cv_results_['std_test_score'][best_score_idx]\n",
    "print(best_score_idx, best_model_roc_auc, best_model_std)\n",
    "print(best_model_std < 5*10**-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "**Question 5.** *Feature importance* is defined by the absolute value of its corresponding coefficient. First, you need to normalize all of the feature values so that it will be valid to compare them (here you resort to `StandardScaler`). What is the most important feature for the best logistic regression model?\n",
    "\n",
    "1. age\n",
    "2. **NumberOfTime30-59DaysPastDueNotWorse**\n",
    "3. DebtRatio\n",
    "4. NumberOfTimes90DaysLate\n",
    "5. NumberOfTime60-89DaysPastDueNotWorse\n",
    "6. MonthlyIncome\n",
    "7. NumberOfDependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfTime30-59DaysPastDueNotWorse\n",
      "[[-0.41630368  0.72400432 -0.02408186  0.51767292  0.19473217 -0.16286353\n",
      "   0.10132603]]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X.values)\n",
    "\n",
    "best_lr = clf.best_estimator_.fit(X_scaled, y.values)\n",
    "most_imp_feat_idx = np.argmax(best_lr.coef_)\n",
    "\n",
    "print(X.columns[most_imp_feat_idx])\n",
    "print(best_lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** What's the effect of  `DebtRatio` on the prediction made with Logistic regression? Calculate this with the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "\n",
    "1. 0.38\n",
    "2. -0.02\n",
    "3. **0.11**\n",
    "4. 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07715192 0.2413105  0.11420537 0.19632139 0.14213998 0.09940641\n",
      " 0.12946443]\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "idx = list(X.columns).index('DebtRatio')\n",
    "print(softmax(best_lr.coef_).flatten())\n",
    "print(np.around(softmax(best_lr.coef_).flatten()[idx], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Let's see how we can interpret the impact of our features. For this, re-train logistic regression with original features, that is, not scaled. Next, modify the customer's age by adding 20 years, keeping the other features unchanged. You'll have two estimates for odds of this customer being bad – with original age and with aged increased by 20 years. What's the quotient of this odds? (the second divided by the first). That is, you'll find how more or less likely it is that a customer won't repay his/her credit if he/she were 20 years older. You can find some material on interpreting logistic regression coefficients [here](https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf).\n",
    "\n",
    "1. -0.01\n",
    "2. 0.70\n",
    "3. 8.32\n",
    "4. 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8091261973940962 0.8091390788209012 1.000015920170236\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr1 = clf.best_estimator_.fit(X.values, y.values)\n",
    "X_20 = X.copy()\n",
    "X_20['age'] = X_20['age'] + 20\n",
    "# print(X['age'])\n",
    "# print(X_20['age'])\n",
    "y_prob1 = lr1.predict_proba(X.values)[:, 1]\n",
    "y_prob2 = lr1.predict_proba(X_20.values)[:, 1]\n",
    "\n",
    "print(roc_auc_score(y.values, y_prob1), roc_auc_score(y.values, y_prob2), \\\n",
    "      roc_auc_score(y.values, y_prob2)/roc_auc_score(y.values, y_prob1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Random Forest with 100 trees and balance target classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42, \n",
    "                            class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to search for the best hyperparameters among these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_features': [1, 2, 4], \n",
    "              'min_samples_leaf': [3, 5, 7, 9], \n",
    "              'max_depth': [5,10,15]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will use stratified k-fold validation again. You should still have the `skf` variable defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** How much higher is the *ROC AUC* of the best random forest model than that of the best logistic regression on validation? Use `GridSearchCV` and it's attribute `best_score_`.\n",
    "\n",
    "1. **0.04**\n",
    "2. 0.03\n",
    "3. 0.02\n",
    "4. 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 7}\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=10, max_features=2,\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=7,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=-1, oob_score=False, random_state=42,\n",
      "            verbose=0, warm_start=False) 0.8350557274994249\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "clf_rf = GridSearchCV(rf, parameters, cv=skf, scoring='roc_auc', verbose=1, n_jobs=-1).fit(X.values, y.values)\n",
    "print(clf_rf.best_params_) \n",
    "print(clf_rf.best_estimator_, clf_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350557274994249 0.7954977787123253 diff 0.03955794878709962\n"
     ]
    }
   ],
   "source": [
    "print(clf_rf.best_score_, clf.best_score_, 'diff', clf_rf.best_score_ - clf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9.** What feature has the weakest impact in the Random Forest model?\n",
    "\n",
    "1. age\n",
    "2. NumberOfTime30-59DaysPastDueNotWorse\n",
    "3. DebtRatio\n",
    "4. NumberOfTimes90DaysLate\n",
    "5. NumberOfTime60-89DaysPastDueNotWorse\n",
    "6. MonthlyIncome\n",
    "7. **NumberOfDependents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NumberOfDependents'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "idx = np.argmin(clf_rf.best_estimator_.feature_importances_)\n",
    "X.columns[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** What is the most significant advantage of using *Logistic Regression* versus *Random Forest* for this problem?\n",
    "\n",
    "1. Spent less time for model fitting;\n",
    "2. Fewer variables to iterate;\n",
    "3. **Feature interpretability;**\n",
    "4. Linear properties of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules and set up the parameters for bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "\n",
    "parameters = {'max_features': [2, 3, 4], 'max_samples': [0.5, 0.7, 0.9], \n",
    "              'base_estimator__C': [0.0001, 0.001, 0.01, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.** Fit a bagging classifier with `random_state=42`. For the base classifiers, use 100 logistic regressors and use `RandomizedSearchCV` instead of `GridSearchCV`. It will take a lot of time to iterate over all 54 variants, so set the maximum number of iterations for `RandomizedSearchCV` to 20. Don't forget to set the parameters `cv` and `random_state=1`. What is the best *ROC AUC* you achieve?\n",
    "\n",
    "1. **80.75%**\n",
    "2. 80.12%\n",
    "3. 79.62%\n",
    "4. 76.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# lr = LogisticRegression(random_state=5, class_weight='balanced')\n",
    "\n",
    "bclf = BaggingClassifier(lr, n_estimators=100, random_state=42)\n",
    "\n",
    "clf = RandomizedSearchCV(bclf, parameters, cv=skf, scoring='roc_auc', verbose=1, n_iter=20, n_jobs=-1, random_state=1).fit(X.values, y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.001, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=5,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=2,\n",
       "         max_samples=0.7, n_estimators=100, n_jobs=1, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076172570918905"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question 12.** Give an interpretation of the best parameters for bagging. Why are these values of `max_features` and `max_samples` the best?\n",
    "\n",
    "1. For bagging it's important to use as few features as possible;\n",
    "2. Bagging works better on small samples;\n",
    "3. Less correlation between single models;\n",
    "4. **The higher the number of features, the lower the loss of information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
